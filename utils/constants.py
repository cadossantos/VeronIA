"""Constantes centralizadas para o projeto VeronIA."""

# ConfiguraÃ§Ãµes padrÃ£o de modelos
DEFAULT_PROVIDER = 'Groq'
DEFAULT_MODEL = 'llama-3.3-70b-versatile'

# ConfiguraÃ§Ãµes de chat
CHAT_MESSAGE_LIMIT = 10
TITLE_TRUNCATE_LENGTH = 30

# ConfiguraÃ§Ãµes de interface
CHAT_INPUT_PLACEHOLDER = 'Fale com a JibÃ³IA...'
HEADER_TITLE = 'ğŸ”® JibÃ³IA'

# Mensagens do sistema
INITIALIZING_MESSAGE = "ğŸš€ **Inicializando JibÃ³IA...** Por favor, aguarde alguns segundos."
WELCOME_MESSAGE = "ğŸ‘‹ OlÃ¡! Sou a JibÃ³IA. Como posso ajudar?"
USAGE_INSTRUCTIONS = """

âš™ï¸ **ConfiguraÃ§Ãµes AvanÃ§adas**
VocÃª pode ajustar as respostas da JibÃ³IA conforme sua necessidade:

ğŸ”¥ Temperatura (0.0 a 1.0):
Define o nÃ­vel de criatividade das respostas.

Mais baixa (ex: 0.2): Respostas mais diretas e objetivas.

Mais alta (ex: 0.8): Respostas mais criativas e diversas.
Valor atual: 0.70 (bom equilÃ­brio entre coerÃªncia e criatividade).

ğŸ§® MÃ¡ximo de tokens (100 a 4000):
Controla o tamanho da resposta da IA.

Menor valor: Respostas mais curtas.

Maior valor: Respostas mais longas e detalhadas.
Valor atual: 1000 tokens (aproximadamente 750 palavras).

ğŸ’¡ **Dica:** Use a aba 'Config' para trocar de modelo.
"""

# ConfiguraÃ§Ãµes de API
API_KEY_TEMPLATE = "{provider}_API_KEY"

# ConfiguraÃ§Ãµes de banco de dados
DATABASE_PATH = "db/veronia.db"