from dotenv import load_dotenv
import os
import time
import streamlit as st

from langchain.memory import ConversationBufferMemory
from langchain.prompts import ChatPromptTemplate

from db.db_sqlite import *
from utils.configs import *

load_dotenv()

def criar_header_fixo():
    """Renderiza um cabe√ßalho fixo com informa√ß√µes do modelo de IA."""
    modelo = st.session_state.get('modelo_nome', 'Modelo n√£o carregado')

    st.markdown("""
    <style>
    .fixed-header {
        position: fixed;
        top: 0;
        left: 1;
        right: 0;
        z-index: 999;
        background: linear-gradient(90deg, #667eea, #764ba2);
        padding: 15px 10px 0px 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border-radius: 30%;
        margin-top: 10px;
    }

    .fixed-header small {
        display: block;
        margin: 10% 0;
        font-size: 16px;
        color: #eeeeee;
    }

    .fixed-header-content {
        display: flex;
        justify-content: center;
        align-items: center;
        color: white;
        font-family: sans-serif;
    }

    .chat-main-area {
        margin-top: 100px; /* Ajustado para compensar o padding maior */
    }
    </style>
    """, unsafe_allow_html=True)

    st.markdown(f"""
    <div class="fixed-header">
        <div class="fixed-header-content">
            <div style="text-align: center;">
                <br>
                <small>{modelo}</small>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)

# INICIALIZA√á√ÉO ==================================================
def inicializacao():
    """Prepara o ambiente da aplica√ß√£o na inicializa√ß√£o.

    Esta fun√ß√£o √© crucial e executa duas tarefas principais:
    1.  `init_database()`: Garante que o banco de dados e suas tabelas
        estejam prontos para uso, criando-os se necess√°rio.
    2.  Popula o `st.session_state`: O `session_state` √© o mecanismo
        do Streamlit para manter dados persistentes entre as intera√ß√µes
        do usu√°rio. Esta fun√ß√£o define valores padr√£o para chaves essenciais
        (como 'memoria', 'chain', 'conversa_atual') na primeira vez que o
        usu√°rio abre a aplica√ß√£o, evitando que o estado seja perdido a cada
        a√ß√£o na UI.
    """
    
    # 1. Primeiro, inicializa o banco
    try:
        init_database()
    except Exception as e:
        st.error(f"‚ùå Erro ao inicializar banco de dados: {e}")
        # N√£o usamos st.stop() aqui para permitir que o app continue, mas com erro vis√≠vel.
        # O usu√°rio precisar√° resolver o problema do banco para usar a funcionalidade.
        return # Sai da fun√ß√£o inicializacao se houver erro no banco
    
    # 2. Configura√ß√µes padr√£o do session state
    defaults = {
        'mensagens': [],
        'conversa_atual': '',
        'api_key': os.getenv("OPENAI_API_KEY", ""),
        'memoria': None, # A mem√≥ria ser√° inicializada na p√°gina do agente
        'chain': None, # A chain ser√° inicializada na p√°gina do agente
        'modelo_nome': 'Nenhum modelo carregado',
        'provedor': 'OpenAI',  # Provedor padr√£o
        'modelo': 'gpt-4o-mini'  # Modelo padr√£o
    }
    
    # 3. Aplica os valores padr√£o apenas se n√£o existirem
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value
    
    print("‚úÖ Inicializa√ß√£o conclu√≠da")

def carrega_modelo(provedor, modelo, api_key=None):
    """Configura e instancia o modelo de linguagem selecionado pelo usu√°rio."""
    system_prompt = f'''
        Voc√™ √© um assistente atencioso aos detalhes.
        '''

    template = ChatPromptTemplate.from_messages([
        ('system', system_prompt),
        ('placeholder', '{chat_history}'),
        ('user', '{input}')
    ])

    chat_class = config_modelos[provedor]['chat']
    
    if provedor == 'Ollama':
        chat = chat_class(model=modelo)
    else:
        api_key = os.getenv(f"{provedor.upper()}_API_KEY")
        if not api_key:
            st.error(f"API key para {provedor} n√£o encontrada no .env.")
        chat = chat_class(model=modelo, api_key=api_key)
    
    chain = template | chat
    st.session_state['chain'] = chain
    st.session_state['modelo_nome'] = f"{provedor} - {modelo}"

def inicia_nova_conversa():
    """Cria e carrega uma nova sess√£o de conversa."""
    memoria = ConversationBufferMemory(return_messages=True)
    st.session_state['memoria'] = memoria

    provedor = st.session_state.get('provedor', 'Groq')
    modelo = st.session_state.get('modelo', 'llama-3.1-8b-instant')
    conversa_id = criar_conversa('Nova conversa', provedor, modelo)

    st.session_state['conversa_atual'] = conversa_id

    if 'titulo_atualizado' in st.session_state:
        del st.session_state['titulo_atualizado']

def inicializa_jiboia():
    """Inicializa modelo padr√£o, mas n√£o cria conversa at√© o usu√°rio interagir."""
    if not st.session_state.get('chain'):
        provedor = 'Groq'
        modelo = 'llama-3.1-8b-instant'
        st.session_state['provedor'] = provedor
        st.session_state['modelo'] = modelo
        try:
            carrega_modelo(provedor, modelo)
        except Exception as e:
            pass


def seleciona_conversa(conversa_id):
    """Carrega o hist√≥rico de uma conversa existente para a mem√≥ria."""
    mensagens = carregar_mensagens(conversa_id)

    memoria = ConversationBufferMemory(return_messages=True)
    for m in mensagens:
        if m['role'] == 'user':
            memoria.chat_memory.add_user_message(m['content'])
        else:
            memoria.chat_memory.add_ai_message(m['content'])

    st.session_state['memoria'] = memoria
    st.session_state['conversa_atual'] = conversa_id

def tab_conversas(tab):
    """Renderiza a aba de gerenciamento de conversas na barra lateral."""
    tab.button('‚ûï Nova conversa', on_click=inicia_nova_conversa, use_container_width=True)
    tab.markdown('')

    conversas = listar_conversas()
    for id, titulo in conversas:
        if len(titulo) == 30:
            titulo += '...'
        tab.button(
            titulo,
            key=f"conversa_{id}",
            on_click=seleciona_conversa,
            args=(id,),
            disabled=id == st.session_state.get('conversa_atual'),
            use_container_width=True
        )
    


def tab_configuracoes(tab):
    """Renderiza a aba de configura√ß√µes do modelo na barra lateral."""
    provedor = tab.selectbox('Selecione o provedor', config_modelos.keys())
    modelo_escolhido = tab.selectbox('Selecione o modelo', config_modelos[provedor]['modelos'])

    conversa_id = st.session_state.get('conversa_atual')
    if conversa_id:
        titulo_atual = get_titulo_conversa(conversa_id)
        novo_titulo = tab.text_input("Renomear conversa atual:", value=titulo_atual, key="input_titulo")
        if tab.button("Salvar t√≠tulo", use_container_width=True, key="salva_titulo"):
            if novo_titulo.strip():
                atualizar_titulo_conversa(conversa_id, novo_titulo.strip())
                seleciona_conversa(conversa_id)
                st.rerun()

    st.session_state['modelo'] = modelo_escolhido
    st.session_state['provedor'] = provedor

    if tab.button('Aplicar Modelo', use_container_width=True):
        carrega_modelo(provedor, modelo_escolhido)

def interface_chat():
    """Interface principal de chat da Jib√≥IA."""
    criar_header_fixo()  # <- chama o header fixo antes de tudo

    st.markdown('<div class="chat-main-area">', unsafe_allow_html=True)
    st.header('üîÆ Jib√≥IA - Ver√¥nIA', divider=True)

    
    # Verifica se o modelo foi configurado
    chain = st.session_state.get('chain')
    if not chain:
        st.info("üöÄ **Inicializando Jib√≥IA...** Por favor, aguarde alguns segundos.")

    # Verifica se existe uma conversa ativa e mem√≥ria
    memoria = st.session_state.get('memoria')
    conversa_atual = st.session_state.get('conversa_atual')

    if not conversa_atual and not memoria:
        st.info("üëã Ol√°! Sou a Jib√≥IA. Me diga como posso ajudar e criarei uma nova conversa para voc√™.")

        # Mensagem informativa sobre modelo padr√£o
        if st.session_state.get('modelo_nome') == 'Groq - llama-3.1-8b-instant':
            st.info("üí° Voc√™ est√° usando o modelo padr√£o (Groq - llama-3.1-8b-instant). A qualquer momento, altere na aba ‚öôÔ∏è Config.")


        # Bot√£o de ajuda
        with st.expander("‚ùì Como usar"):
            st.markdown("""
            **Jib√≥IA est√° pronta para uso:**
            1. ‚úÖ Modelo j√° carregado automaticamente!
            2. ‚úÖ Conversa iniciada automaticamente!
            3. üöÄ Comece a conversar agora mesmo!
            
            üí° **Dica:** Use a aba 'Config' para trocar de modelo.
            """)

    else:
        if not memoria or not hasattr(memoria, "buffer_as_messages"):
            st.error("‚ùå Problema com a mem√≥ria da conversa")
            st.stop()


    # Sidebar
    with st.sidebar:
        st.title("üîÆ Jib√≥IA")
        tab1, tab2 = st.sidebar.tabs(['üí¨ Conversas', '‚öôÔ∏è Config'])
        tab_conversas(tab1)
        tab_configuracoes(tab2)
                

    # Renderiza hist√≥rico de mensagens
    if memoria and hasattr(memoria, "buffer_as_messages"):
        for mensagem in memoria.buffer_as_messages:
            chat = st.chat_message(mensagem.type)
            chat.markdown(mensagem.content)

    # Campo de entrada do usu√°rio
    input_usuario = st.chat_input('Fale com a Jib√≥IA...')

    if input_usuario:
        # Cria nova conversa e mem√≥ria se ainda n√£o existirem
        if not st.session_state.get('conversa_atual') or not st.session_state.get('memoria'):
            inicia_nova_conversa()

        memoria = st.session_state.get('memoria')
        conversa_atual = st.session_state.get('conversa_atual')

        if memoria is None:
            st.error("‚ùå Falha ao iniciar a mem√≥ria da conversa. Tente recarregar a p√°gina.")
            st.stop()

        tempo_inicial = time.time()

        # Exibe mensagem do usu√°rio
        chat = st.chat_message('human')
        chat.markdown(input_usuario)

        # Gera resposta da IA
        chat = st.chat_message('ai')
        chat_history = memoria.buffer_as_messages if hasattr(memoria, "buffer_as_messages") else []
        resposta = chat.write_stream(st.session_state['chain'].stream({
            'input': input_usuario,
            'chat_history': chat_history
        }))

        # Tempo de resposta
        tempo_final = time.time()
        with st.sidebar:
            st.caption(f'‚è±Ô∏è Tempo: {tempo_final - tempo_inicial:.2f}s')

        # Atualiza mem√≥ria
        memoria.chat_memory.add_user_message(input_usuario)
        memoria.chat_memory.add_ai_message(resposta)
        st.session_state['memoria'] = memoria

        # Atualiza t√≠tulo
        if 'titulo_atualizado' not in st.session_state:
            atualizar_titulo_conversa(conversa_atual, input_usuario[:30])
            st.session_state['titulo_atualizado'] = True

        # Persist√™ncia no banco
        salvar_mensagem(conversa_atual, 'user', input_usuario)
        salvar_mensagem(conversa_atual, 'assistant', resposta)


    st.markdown('</div>', unsafe_allow_html=True)


# MAIN ==================================================
def main():
    """Ponto de entrada principal da aplica√ß√£o Streamlit.

    Configura a p√°gina (t√≠tulo, √≠cone) e organiza o layout, definindo a
    barra lateral com suas abas e chamando a `pagina_principal` para
    renderizar o conte√∫do central.
    """
    st.set_page_config(
        page_title="Jib√≥IA - Ver√¥nIA",
        page_icon="üîÆ",
        layout="wide"
    )
    
    # Inicializa tudo
    inicializacao()
    inicializa_jiboia()
    
    # Interface principal da Jib√≥IA
    interface_chat()
    
if __name__ == '__main__':
    main()